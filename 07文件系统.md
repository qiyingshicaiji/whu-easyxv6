# 实验7：文件系统（报告草稿·第1部分）

## 一、实验概述

### 实验目标
通过分析并实现一个简化版 xv6 风格文件系统，理解：
- 磁盘布局（super/log/inode/bitmap/data）
- inode 与目录项组织方式
- 块缓存（buffer cache）与磁盘 I/O
- 写前日志（WAL, Write-Ahead Logging）的基本提交与恢复流程
- 从系统调用 `open/read/write` 到落盘的完整调用链路

### 完成情况（基于本工程代码的实际实现）
- ✅ 文件系统基础结构与布局定义（超级块、inode、目录项、位图）  
- ✅ 块缓存模块 bio.c：LRU 管理 + `bread/bwrite/brelse`  
- ✅ 写前日志模块 log.c：`begin_op/log_write/end_op` + 崩溃恢复  
- ✅ 核心 FS 模块 fs.c：`fs_init/fs_alloc/fs_free`、inode 管理、目录/路径解析  
- ✅ 文件描述符层 file.c：文件表、`file_read/file_write`（按日志容量分片提交）  
- ✅ 系统调用层 sysfile.c：`open/close/read/write/mkdir/link/unlink/fstat/dup`
- 
## 二、技术设计

### 2.1 系统整体分层（从系统调用到磁盘）
本工程从上到下的大致路径如下：

```
用户程序
  ↓ (ecall)
sysfile.c: sys_open/sys_read/sys_write/...
  ↓
file.c: file_read/file_write (维护 off、append 等语义)
  ↓
fs.c: readi/writei → bmap → fs_alloc/fs_free → iupdate/dirlink/namei
  ↓
log.c: begin_op/log_write/end_op → commit()
  ↓
bio.c: bread/bwrite → virtio_disk_rw
  ↓
virtio_disk.c: virtio 队列 + MMIO 通知 → QEMU virtio-blk
```

该分层对应“文件语义层（fd/file）→ 元数据/数据管理（inode/dir/bitmap）→ 一致性（log）→ I/O 缓存（bio）→ 设备驱动（virtio）”。

---

### 2.2 文件系统布局（Disk Layout）
工程在 include/fs/fs.h 中给出了经典布局注释：

```
[ boot block | super block | log | inode blocks | free bit map | data blocks ]
```

关键常量（本工程取值）：
- 块大小：`BSIZE = 1024`
- 文件系统总块数：`FSSIZE = 1000`
- 日志块数：`LOGSIZE = 30`
- 根 inode：`ROOTINO = 1`，根设备：`ROOTDEV = 1`

在 kernel/fs/fs.c 的 `fs_init()` 中，如果读取到的超级块 `magic != FSMAGIC`，则会“创建新文件系统”，并设置超级块各字段：
- `sb.size = FSSIZE`
- `sb.nblocks = FSSIZE - 100`（预留部分给元数据，属于简化估算）
- `sb.ninodes = 200`
- `sb.nlog = 30`
- `sb.logstart = 2`
- `sb.inodestart = 2 + sb.nlog`
- `sb.bmapstart = sb.inodestart + sb.ninodes / IPB + 1`

随后会：
1) `log_init(dev, &sb)` 初始化日志并执行恢复  
2) 初始化位图：把 0 到 `sb.bmapstart` 的系统块标记为已使用  
3) 创建根目录 inode，并写入 `.` 与 `..` 两个目录项

---

### 2.3 关键数据结构（与代码一致）

#### 1）超级块 `superblock`
定义在 include/fs/fs.h：
```c
struct superblock {
    uint64 magic;
    uint64 size;
    uint64 nblocks;
    uint64 ninodes;
    uint64 nlog;
    uint64 logstart;
    uint64 inodestart;
    uint64 bmapstart;
};
```

作用理解：
- `magic`：判断磁盘上是否已经存在可用文件系统
- `size`：总块数，用于范围检查（例如缓存层 `bget` 会检查 `blockno >= FSSIZE`）
- `logstart/nlog`：日志区范围，用于 WAL
- `inodestart/ninodes`：inode 区范围，用于 `IBLOCK(inum, sb)`
- `bmapstart`：位图区起始，用于 `BBLOCK(b, sb)`

#### 2）磁盘 inode `dinode` 与内存 inode `inode`
磁盘 inode（持久化）与内存 inode（缓存）分别是：
- include/fs/fs.h `struct dinode`
- include/fs/fs.h `struct inode`

本工程 inode 使用：
- `NDIRECT = 12` 个直接块指针
- `addrs[NDIRECT]` 位置存放“一级间接块”的块号（因此数组大小为 `NDIRECT+1`）
- 最大文件块数：`MAXFILE = NDIRECT + NINDIRECT`

对应的块映射逻辑在 kernel/fs/fs.c 的 `bmap()`：
- `bn < NDIRECT`：走直接块
- 否则走一级间接块（无二级间接）

#### 3）目录项 `dirent`
定义在 include/fs/fs.h：
```c
struct dirent {
    uint64 inum;
    char name[DIRSIZ]; // DIRSIZ=14
};
```

目录文件本质上是“由多个 `dirent` 顺序组成的普通文件”，查找与插入分别由：
- kernel/fs/fs.c `dirlookup()`
- kernel/fs/fs.c `dirlink()`

---

## 三、实现细节

### 3.1 文件系统初始化 `fs_init(dev)`
位于 kernel/fs/fs.c：

核心流程（与代码一致）：
1. `bio_init()`：初始化块缓存 + `virtio_disk_init()`
2. 读取块 1 的超级块（`bread(dev, 1)` → `memmove(&sb, bp->data, sizeof(sb))`）
3. 若 `sb.magic != FSMAGIC`：格式化（写超级块、标记位图、创建根目录）
4. 调 `log_init(dev, &sb)`：启动时执行 `recover_from_log()`（见下一部分会展开）

### 3.2 空闲块管理：位图 + `fs_alloc/fs_free`
位于 kernel/fs/fs.c：

- `fs_alloc(dev)`：
  - 扫描位图块（每块 `BPB = BSIZE*8` 个 bit）
  - 找到空闲 bit 后置 1，并 `log_write(bp)` 纳入事务
  - 再把新分配的数据块清零（读该块→`memset`→`log_write`）
- `fs_free(dev, b)`：
  - 清对应位图 bit，并 `log_write(bp)`

注意：这里所有对位图、数据块清零的修改都走 `log_write`，意味着它们会通过 WAL 提交保证一致性。


### 3.3 块缓存系统（Buffer Cache，bio）

对应代码：
- 块缓存实现：kernel/fs/bio.c
- 缓冲块结构定义：include/fs/bio.h
- 底层磁盘读写驱动：kernel/dev/virtio_disk.c

#### 3.3.1 缓存结构与关键字段
本工程的缓存块结构（摘自 include/fs/bio.h）核心字段：
- `dev` / `blockno`：缓存条目标识（哪个设备的哪个块）
- `valid`：缓存中是否已有有效数据（没有则需从磁盘读入）
- `refcnt`：引用计数（有人在用就不能被替换）
- `prev/next`：双向链表指针，用于 LRU 管理
- `data[BSIZE]`：实际块数据

缓存总量 `NBUF=30`（见 kernel/fs/bio.c），属于一个非常小但足以说明机制的配置。

#### 3.3.2 LRU 管理策略
在 kernel/fs/bio.c 中，`bcache.head` 是一个环形双向链表的哨兵节点：
- 链表头附近表示“最近使用”
- 链表尾附近表示“最久未使用”
- `brelse()` 在 `refcnt` 降到 0 时，把该 buf 移动到链表头（标记为最近使用）

这是一种经典简化 LRU：用“释放时前移”近似表达近期使用度。

#### 3.3.3 三个核心 API：bread / bwrite / brelse
1) `bread(dev, blockno)`（读块）
- 内部先 `bget(dev, blockno)`：
  - 若缓存命中：`refcnt++` 直接返回
  - 若不命中：从 LRU 尾部找 `refcnt==0` 的 buf 复用，并设置 `valid=0`
- 若 `valid==0`：调用 `virtio_disk_rw(b, 0)` 从磁盘读入，再置 `valid=1`

2) `bwrite(b)`（写块）
- 直接 `virtio_disk_rw(b, 1)` 写入磁盘

3) `brelse(b)`（释放块）
- `refcnt--`
- 若 `refcnt==0`：将 buf 移到 LRU 头（近期使用）

#### 3.3.4 与日志系统的配合：bpin / bunpin
日志系统需要保证：事务提交安装完成之前，被记录的块不能被缓存替换掉。
- `log_write(b)` 会对“新加入事务的块”调用 `bpin(b)`（等价于 `refcnt++`）
- 在安装（install）完成后 `bunpin(b)`（等价于 `refcnt--`）

对应实现：
- `bpin/bunpin` 在 kernel/fs/bio.c
- 调用点在 kernel/fs/log.c 的 `log_write()` 与 `install_trans()`


### 3.4 写前日志（WAL，log）

对应代码：
- 日志实现：kernel/fs/log.c
- 接口定义：include/fs/log.h

本工程日志系统的目标是：把一次文件系统操作（或多次操作聚合）包装成一个事务，使其满足“要么全部生效，要么全部不生效”，并在崩溃后能恢复到一致状态。

#### 3.4.1 日志的基本数据结构
日志头 `logheader`（在 kernel/fs/log.c）：
- `n`：本次事务记录了多少个块
- `block[i]`：第 i 个被修改的“目标块号”（注意：这里记的是“真实块号”，不是日志区块号）

全局日志上下文 `log_ctx` 记录：
- `start`：日志起始块号（来自超级块 `sb.logstart`）
- `size`：日志区大小（来自 `sb.nlog`）
- `outstanding`：当前正在进行的 FS 操作数（用于分组提交）
- `committing`：是否正在提交（用于互斥）

#### 3.4.2 事务 API：begin_op / log_write / end_op
- `begin_op()`：开始一次文件系统操作
  - 若 `committing==1`，自旋等待（本工程简化为 busy-wait）
  - 若预计会超过日志容量，也会自旋等待
  - 否则 `outstanding++` 允许进入事务

- `log_write(b)`：声明“这个缓存块被修改过，需要写入事务”
  - 检查必须在事务内（`outstanding>=1`）
  - 去重：若该 blockno 已在 `lh.block[]` 中出现，则只记录一次
  - 新记录时 `bpin(b)`，避免提交前被替换

- `end_op()`：结束一次文件系统操作
  - `outstanding--`
  - 当 `outstanding==0` 时触发一次 `commit()`

这里的设计要点是：多个系统调用如果并发进入文件系统，可以被合并在同一次 commit 里（虽然本工程未加锁/睡眠队列，逻辑上仍体现了 xv6 的“outstanding 聚合提交”思想）。

#### 3.4.3 四步提交协议（commit）
`commit()` 在 kernel/fs/log.c 中实现，流程非常清晰（并且代码里也有注释）：

```
commit():
  1) write_log()     把“缓存中的新数据”拷贝到“日志区”
  2) write_head()    把日志头写到磁盘（这是提交点）
  3) install_trans() 把日志区的数据写回到各自真实块号
  4) write_head()    清空日志头（n=0），表示事务完成
```

其中：
- `write_log()`：日志区的数据块从 `log_ctx.start + 1` 开始依次写（头块在 `start`）
- `write_head()`：把 `n` 和 `block[]` 写入日志头所在块 `log_ctx.start`
- `install_trans(recovering)`：把日志数据复制回 `lh.block[i]` 指向的真实块，并在非恢复场景下 `bunpin(dbuf)`

**一致性关键点（提交点）**  
`write_head()` 把“本次事务包含哪些块”写入磁盘后，即使系统崩溃，重启也能知道“有一笔已提交但未安装完的事务”，从而在恢复阶段把它安装回去，保证文件系统处于一致状态。

#### 3.4.4 崩溃恢复（recover_from_log）
`log_init()` 会调用 `recover_from_log()`（在 kernel/fs/log.c）：
1) `read_head()` 读日志头
2) `install_trans(1)`：把日志区内容安装到真实块（如果 `n>0`）
3) 清空 `lh.n=0` 并 `write_head()`，抹掉日志（恢复完成）

这保证了：只要日志头落盘，恢复就能“重放”事务，且多次重放仍是幂等的（同一数据覆盖同一位置）。

---

## 四、小结（本部分）
- 块缓存提供“热点块复用 + 降低 I/O”的基本能力，并通过 `refcnt/LRU` 管理替换。
- WAL 提供“元数据/数据一致性”的核心保障：先把修改写到日志区，再写头提交，最后安装到真实位置。
- `bpin/bunpin` 是 bio 与 log 的关键连接点：保证事务涉及的 buf 不会在安装前被替换。

---

## 五、实现细节

### 5.1 inode 缓存与生命周期管理

对应代码：
- inode 结构与布局：include/fs/fs.h
- inode 分配/缓存/回收：kernel/fs/fs.c

#### 5.1.1 内存 inode 缓存（icache）
本工程使用一个固定大小的 inode 缓存数组：
- `NINODE = 100`（见 kernel/fs/fs.c）
- `iget(dev, inum)`：优先命中缓存；否则找空槽位复用

`iget()` 的关键语义：
- 命中：`ref++`，返回同一个内存 inode
- 未命中：找 `ref==0` 的空槽，把 `dev/inum/ref=1/valid=0` 填好返回

说明：该实现没有 xv6 里的全局锁与 LRU/哈希细节，属于“教学简化版 inode cache”。

#### 5.1.2 ilock/iunlock 的简化实现
在 kernel/fs/fs.c 中：
- `ilock(ip)` 在 `ip->valid==0` 时从磁盘 inode 区读取 dinode，并拷贝到内存 inode 字段，再置 `valid=1`
- `iunlock(ip)` 在本工程中是空实现（仅做参数合法性检查）

这表示：
- “锁”的语义主要用于表达“确保 inode 内容已加载/已更新”
- 并发安全在本实验工程里没有做完整实现（与标准 xv6 有差异）

#### 5.1.3 iupdate/iput/itrunc：元数据落盘与回收
1) `iupdate(ip)`（kernel/fs/fs.c）
- 将内存 inode 的 `type/major/minor/nlink/size/addrs[]` 写回到磁盘的 `struct dinode`
- 写回使用 `log_write(bp)`，因此 inode 更新也受 WAL 保护

2) `iput(ip)`（kernel/fs/fs.c）
- 根目录保护：当 `inum==ROOTINO && ref==1` 时直接 `ref--` 返回（避免根被释放）
- 当满足 `ref==1 && valid && nlink==0`：
  - 调用 `itrunc(ip)` 释放所有数据块
  - `ip->type=0` 并 `iupdate(ip)` 把磁盘 inode 标记为空闲
  - `valid=0`
- 最后 `ref--`

3) `itrunc(ip)`（kernel/fs/fs.c）
- 释放 12 个直接块
- 若存在一级间接块：读出间接块数组，释放其中所有数据块，再释放该间接块本身
- `ip->size=0` 并 `iupdate(ip)`

该组合体现了典型 xv6 语义：
- “目录项/硬链接”决定 `nlink`
- “进程是否还持有 fd”等决定 `ref`
- 只有当 `nlink==0` 且没人再引用时才真正回收数据块

---

### 5.2 文件数据块映射与读写路径（bmap/readi/writei）

对应代码：kernel/fs/fs.c

#### 5.2.1 bmap：逻辑块号 → 物理块号
`bmap(ip, bn)` 的输入 `bn` 是“文件内逻辑块号”（`off/BSIZE`），输出是磁盘物理块号。

实现要点：
- `bn < NDIRECT`：直接块，若 `addrs[bn]==0` 则 `fs_alloc()` 分配
- 否则进入一级间接：
  - 若 `addrs[NDIRECT]==0` 先分配间接块
  - 在间接块内用 `a[bn-NDIRECT]` 存放数据块号；缺失则分配并 `log_write(bp)`
- 超过 `MAXFILE` 范围直接 `panic("bmap: out of range")`

这种“按需分配”的策略对小文件非常友好：
- 小文件通常只用直接块，元数据开销小
- 大文件通过间接块扩展，但本工程仅支持一级间接

#### 5.2.2 readi：从 inode 读取（支持用户/内核目的地址）
`readi(ip, user_dst, dst, off, n)`：
- 检查 `off` 与 `ip->size`，必要时裁剪 `n`
- 循环逐块读取：
  - `bread(ip->dev, bmap(ip, off/BSIZE))`
  - 计算本块可读字节 `m = min(n-tot, BSIZE-off%BSIZE)`
  - 若 `user_dst==1`：用 `uvm_copyout(p->pgtbl, dst, src, m)`
  - 否则 `memmove((void*)dst, src, m)`

#### 5.2.3 writei：向 inode 写入（支持用户/内核源地址）
`writei(ip, user_src, src, off, n)`：
- 检查越界：`off+n` 不能超过 `MAXFILE * BSIZE`
- 循环逐块写：
  - `bread(..., bmap(...))`（必要时触发块分配）
  - 若 `user_src==1`：`uvm_copyin(p->pgtbl, dst, src, m)`
  - 否则 `memmove(dst, (void*)src, m)`
  - 对该数据块 `log_write(bp)`（关键：数据块也纳入 WAL）
- 若扩展了文件：更新 `ip->size` 并 `iupdate(ip)`

---

### 5.3 目录操作与路径解析（dirlookup/dirlink/namei）

对应代码：kernel/fs/fs.c

#### 5.3.1 目录项查找：dirlookup
`dirlookup(dp, name, &off)`：
- 要求 `dp->type==T_DIR`
- 从 `off=0` 遍历到 `dp->size`，每次读一个 `struct dirent`
- 跳过 `inum==0` 的空洞项
- 命中则返回 `iget(dp->dev, de.inum)`，并可选返回目录项偏移 `off`

该实现体现“目录就是普通文件”：
- 目录项连续存储
- 删除时只是把某个目录项清零（形成空洞）

#### 5.3.2 创建目录项：dirlink
`dirlink(dp, name, inum)`：
- 若 `dirlookup` 已存在同名项则失败
- 从头扫描找第一个 `inum==0` 的空洞；找不到则在 `dp->size` 末尾追加
- 写入 `de.name/de.inum`，通过 `writei()` 落盘（因此也会走 WAL）

#### 5.3.3 路径解析：namei/nameiparent/namex
路径解析的核心是：
- `skipelem(path, name)`：跳过连续 `/`，取出一个路径组件到 `name`
- `namex(path, nameiparent, name)`：从根目录开始逐级 `dirlookup`

本工程的简化点：
- 不维护每进程 cwd；非绝对路径也被简化为从根开始（代码里注释：当前目录就是根目录）

语义：
- `namei(path)`：返回最终目标 inode
- `nameiparent(path, name)`：返回父目录 inode，并把最后一级名字写入 `name`

---

### 5.4 系统调用层：create/link/unlink 与硬链接语义

对应代码：kernel/syscall/sysfile.c

#### 5.4.1 create + open：创建文件/目录的基本流程
`sys_open()`：
- 若 `O_CREATE`：调用 `create(path, T_FILE, ...)`
- 否则 `namei(path)` 找到 inode
- 分配 `struct File`（全局文件表）和 fd（进程 `ofile[]`）

`create()`：
1) 用 `nameiparent(path, name)` 找父目录 dp
2) `dirlookup(dp, name)` 检查是否已存在
3) `ialloc(dp->dev, type)` 分配新 inode，设置 `nlink=1`，并 `iupdate`
4) 若是目录：
   - 父目录 `dp->nlink++` 并更新
   - 给新目录创建 `.` 和 `..`（通过 `dirlink`）
5) 在父目录中 `dirlink(dp, name, ip->inum)` 建立目录项

整个 create/open/mkdir 路径都包在 `begin_op()`/`end_op()` 内，从而保证它们作为事务提交。

#### 5.4.2 硬链接 sys_link：增加一个目录项引用同一 inode
`sys_link(old, new)`：
1) `namei(old)` 得到 inode `ip`，拒绝对目录做硬链接
2) `ip->nlink++` 并 `iupdate(ip)`
3) `nameiparent(new, name)` 得到新父目录 dp
4) `dirlink(dp, name, ip->inum)`：在新路径处添加目录项，指向同一 inode

失败回滚：若新目录项创建失败，会把 `nlink--` 写回，保证链接计数一致。

#### 5.4.3 删除 sys_unlink：清目录项 + nlink-- + 触发回收
`sys_unlink(path)`：
1) 找父目录 dp 与目标名 name，拒绝删除 `.` 和 `..`
2) `dirlookup(dp, name, &off)` 得到 inode ip 与目录项偏移
3) 将目录项内容清零（`memset(&de, 0, sizeof(de))`），并 `writei(dp, ...)` 写回
4) 若目标是目录：需要检查 `isdirempty()`，并且父目录 `dp->nlink--`
5) `ip->nlink--` 并 `iupdate(ip)`，最后 `iput(ip)`

当 `ip->nlink` 被减到 0 且 `ref==1` 时，`iput()` 会调用 `itrunc()` 真正释放数据块并回收 inode。

---

### 5.5 文件写入为何要“分片事务提交”（file_write）

对应代码：kernel/fs/file.c

`file_write()` 中计算了单次事务允许写入的最大字节数：

```c
int max = ((LOGSIZE - 1 - 1 - 2) / 2) * BSIZE;
```

含义（与 xv6 思路一致）：
- 一次写入可能修改：数据块本身 + 位图块 + inode 块等
- 日志容量有限（本工程 `LOGSIZE=30`），因此要把大写入拆成多次 `begin_op/end_op`
- 这样避免“单次事务记录块数超上限”导致 `panic("too big a transaction")`

---

## 六、端到端流程图与总结

本部分把“系统调用 → 文件层 → inode/目录 → 日志 → 块缓存 → virtio 驱动”的关键路径串起来，给出便于复习/答辩的端到端调用链。

---

### 6.1 启动与恢复：fs_init + log_init

对应代码：
- kernel/fs/fs.c：`fs_init()`
- kernel/fs/log.c：`log_init()` / `recover_from_log()`

启动流程（概览）：

```
fs_init(dev)
  ├─ bio_init()
  │    └─ virtio_disk_init()
  ├─ 读 superblock: bread(dev, 1) → memmove(&sb, ...)
  ├─ if (sb.magic != FSMAGIC)
  │    ├─ 写回 superblock
  │    ├─ log_init(dev, &sb)      // 初始化并做一次 recover
  │    ├─ begin_op()
  │    │    └─ 初始化位图：标记 0..sb.bmapstart 为已用（log_write）
  │    ├─ end_op()
  │    ├─ begin_op()
  │    │    └─ ialloc(T_DIR) + dirlink(".")/dirlink("..") 创建根目录
  │    └─ end_op()
  └─ else
    └─ log_init(dev, &sb)
```

恢复流程（log_init 内部）：

```
log_init(dev, sb)
  └─ recover_from_log()
    ├─ read_head()          // 读日志头
    ├─ install_trans(1)     // 把日志块覆盖写回真实块
    └─ write_head(n=0)      // 清日志
```

要点：只要“日志头块”已经落盘（提交点之后），启动时就会重放安装，保证一致性。

---

### 6.2 open/create：从 sys_open 到目录项落盘

对应代码：
- kernel/syscall/sysfile.c：`sys_open()` / `create()`
- kernel/fs/fs.c：`nameiparent()` / `dirlookup()` / `dirlink()` / `ialloc()` / `iupdate()`

流程图：

```
sys_open(path, omode)
  ├─ begin_op()
  ├─ if (O_CREATE)
  │    └─ create(path, T_FILE)
  │         ├─ dp = nameiparent(path, name)
  │         ├─ ilock(dp)
  │         ├─ if exists: dirlookup(dp, name)
  │         ├─ ip = ialloc(dev, type)
  │         ├─ ilock(ip); ip->nlink=1; iupdate(ip)
  │         ├─ if (type==DIR): dirlink(ip, ".") / dirlink(ip, "..")
  │         ├─ dirlink(dp, name, ip->inum)   // 写目录项（writei→log_write）
  │         └─ iunlockput(dp); return ip
  └─ else
    └─ ip = namei(path)
  ├─ f = alloc_file(); fd = fdalloc(f)
  ├─ 设置 f->type/off/readable/writable/append 等
  ├─ iunlock(ip)
  └─ end_op()
```

要点：
- create 过程中对“父目录、子 inode、目录项”的更新都在同一事务中提交。
- `dirlink()` 本质是对目录文件执行一次 `writei()`，因此目录项修改同样走 WAL。

---

### 6.3 write：从 sys_write 到 virtio_disk_rw（含 WAL 提交）

对应代码：
- kernel/syscall/sysfile.c：`sys_write()`
- kernel/fs/file.c：`file_write()`
- kernel/fs/fs.c：`writei()` / `bmap()` / `fs_alloc()` / `iupdate()`
- kernel/fs/log.c：`begin_op()`/`log_write()`/`end_op()`/`commit()`
- kernel/fs/bio.c：`bread()`/`bwrite()`
- kernel/dev/virtio_disk.c：`virtio_disk_rw()`

端到端流程（含分片写入）：

```
sys_write(fd, user_buf, n)
  └─ file_write(f, user_buf, n)
    ├─ max = ...  // 单次事务最大写入字节数（防止日志溢出）
    └─ while (i < n)
      ├─ begin_op()
      ├─ ilock(ip)
      ├─ if append: f->off = ip->size
      ├─ writei(ip, user_src=1, src=user_buf+i, off=f->off, n1)
  │         └─ brelse(bp)
  └─ iunlock(ip)
```
      │         ├─ bp = bread(dev, bno)    // 可能触发 virtio 读
      │         ├─ uvm_copyin(...)         // 用户态数据拷入 bp->data
      │         ├─ log_write(bp)           // 记录被修改的数据块
      │         └─ brelse(bp)
      ├─ 若扩展文件：iupdate(ip)（log_write inode 块）
      ├─ iunlock(ip)
      └─ end_op()
        └─ 若 outstanding==0 触发 commit():
          1) write_log()   // bwrite(日志数据块) → virtio_disk_rw(write)
          2) write_head()  // bwrite(日志头块)   → virtio_disk_rw(write)
          3) install_trans() // bwrite(真实块)  → virtio_disk_rw(write)
          4) write_head(0) // 清头
```

要点：
- `writei()` 对“数据块”调用 `log_write(bp)`，因此本工程是“数据 + 元数据”都写日志的方式。
- `fs_alloc()` 会：修改位图（log_write）+ 清零新数据块（log_write），避免泄漏旧数据。

---

### 6.4 read：从 sys_read 到 virtio_disk_rw

对应代码：kernel/syscall/sysfile.c、kernel/fs/file.c、kernel/fs/fs.c、kernel/fs/bio.c、kernel/dev/virtio_disk.c

流程：

```
sys_read(fd, user_buf, n)
  └─ file_read(f, user_buf, n)
    ├─ ilock(ip)
    ├─ readi(ip, user_dst=1, dst=user_buf, off=f->off, n)
    │    └─ for each block covered:
    │         ├─ bno = bmap(ip, off/BSIZE)   // 注意：bmap 可能按需分配（读路径在本工程中仍会分配块）
    │         ├─ bp = bread(dev, bno)        // 若缓存无效：virtio_disk_rw(read)
    │         ├─ uvm_copyout(...)            // 拷到用户缓冲
    │         └─ brelse(bp)
    └─ iunlock(ip)
```

备注：标准 xv6 的读路径通常不会分配新块；本工程 `readi()` 调用了 `bmap()`，而 `bmap()` 会“缺块即分配”。这属于实现简化导致的语义差异（见 6.6）。

---

### 6.5 unlink：删除路径与空间回收

对应代码：kernel/syscall/sysfile.c、kernel/fs/fs.c

流程：

```
sys_unlink(path)
  ├─ begin_op()
  ├─ dp = nameiparent(path, name)
  ├─ ilock(dp)
  ├─ ip = dirlookup(dp, name, &off)
  ├─ ilock(ip)
  ├─ 若是目录：isdirempty 检查；并维护 dp->nlink
  ├─ 清目录项：writei(dp, &zero_dirent, off, sizeof(de))  // 走 log_write
  ├─ ip->nlink--; iupdate(ip)
  ├─ iunlockput(dp)
  ├─ iunlockput(ip)  // 若 nlink==0 且 ref==1：iput 内触发 itrunc→fs_free
  └─ end_op()        // 触发 commit，位图/数据/inode/目录项 统一提交
```

---

### 6.6 本工程相对 xv6 的简化点与改进方向

#### 6.6.1 主要简化点（有助于理解，但会带来语义/并发差异）
1) 并发与阻塞：
- `begin_op()` 在日志不足或正在提交时采用 busy-wait，没有 sleep/wakeup 机制。
- 缺少对 `log_ctx`、`bcache`、`icache` 的完整并发锁保护（更像单核/无竞争假设）。

2) inode 锁：
- `iunlock()` 基本为空实现，`ilock()` 的作用更接近“确保从磁盘加载一次”。

3) 路径解析：
- 非绝对路径被简化为从根目录开始（不维护进程 cwd）。

4) 读路径语义：
- `readi()` 通过 `bmap()` 获取块号，而 `bmap()` 会在缺失时分配新块，导致“读也可能分配磁盘块”。

5) 元数据特性：
- 未实现权限/时间戳/更完整的 `stat` 等（`file_stat()` 也为简化占位）。

#### 6.6.2 可改进方向（作为扩展/加分点）
- 为 `log_ctx`、`bcache`、`icache` 加自旋锁/睡眠锁，并在 `begin_op()` 引入 sleep/wakeup，避免 busy-wait。
- 将 `bmap()` 拆分为“只查询不分配”的版本，保证读路径不产生分配副作用。
- inode cache 使用哈希桶 + LRU，提高 `iget()` 命中与查找效率。
- 进一步支持二级间接块（double-indirect），提升最大文件尺寸。
- 完善 `stat`、权限位、时间戳等 inode 扩展字段。
- 增加一致性检查工具（类似 fsck 的思路），用于检测位图/inode/目录项不一致。
